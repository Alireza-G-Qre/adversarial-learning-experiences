{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import models, transforms\n",
    "\n",
    "import time\n",
    "import math\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, ConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "torch.cuda.random.manual_seed(0)\n",
    "np.random.seed(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RS-Attack"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class RSAttack:\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            predict,\n",
    "            norm='L0',\n",
    "            n_queries=5000,\n",
    "            eps=None,\n",
    "            p_init=.8,\n",
    "            n_restarts=1,\n",
    "            seed=0,\n",
    "            verbose=True,\n",
    "            targeted=False,\n",
    "            loss='margin',\n",
    "            resc_schedule=True,\n",
    "            device=None,\n",
    "            constant_schedule=False,\n",
    "            init_patches='random_squares',\n",
    "            resample_loc=None,\n",
    "            data_loader=None,\n",
    "            update_loc_period=None):\n",
    "\n",
    "        self.predict = predict\n",
    "        self.norm = norm\n",
    "        self.n_queries = n_queries\n",
    "        self.eps = eps\n",
    "        self.p_init = p_init\n",
    "        self.n_restarts = n_restarts\n",
    "        self.seed = seed\n",
    "        self.verbose = verbose\n",
    "        self.targeted = targeted\n",
    "        self.loss = loss\n",
    "        self.rescale_schedule = resc_schedule\n",
    "        self.device = device\n",
    "        self.logger = logger\n",
    "        self.constant_schedule = constant_schedule\n",
    "        self.init_patches = init_patches\n",
    "        self.resample_loc = n_queries // 10 if resample_loc is None else resample_loc\n",
    "        self.data_loader = data_loader\n",
    "        self.update_loc_period = update_loc_period if not update_loc_period is None else 4 if not targeted else 10\n",
    "\n",
    "    def margin_and_loss(self, x, y):\n",
    "\n",
    "        logits = self.predict(x)\n",
    "        xent = F.cross_entropy(logits, y, reduction='none')\n",
    "        u = torch.arange(x.shape[0])\n",
    "        y_corr = logits[u, y].clone()\n",
    "        logits[u, y] = -float('inf')\n",
    "        y_others = logits.max(dim=-1)[0]\n",
    "\n",
    "        if not self.targeted:\n",
    "            if self.loss == 'ce':\n",
    "                return y_corr - y_others, -1. * xent\n",
    "            elif self.loss == 'margin':\n",
    "                return y_corr - y_others, y_corr - y_others\n",
    "        else:\n",
    "            return y_others - y_corr, xent\n",
    "\n",
    "    def init_hyperparam(self, x):\n",
    "        assert self.norm in ['L0', 'patches', 'frames',\n",
    "                             'patches_universal', 'frames_universal']\n",
    "        assert not self.eps is None\n",
    "        assert self.loss in ['ce', 'margin']\n",
    "\n",
    "        if self.device is None:\n",
    "            self.device = x.device\n",
    "        self.orig_dim = list(x.shape[1:])\n",
    "        self.ndims = len(self.orig_dim)\n",
    "        if self.seed is None:\n",
    "            self.seed = time.time()\n",
    "        if self.targeted:\n",
    "            self.loss = 'ce'\n",
    "\n",
    "    def random_target_classes(self, y_pred, n_classes):\n",
    "        y = torch.zeros_like(y_pred)\n",
    "        for counter in range(y_pred.shape[0]):\n",
    "            l = list(range(n_classes))\n",
    "            l.remove(y_pred[counter])\n",
    "            t = self.random_int(0, len(l))\n",
    "            y[counter] = l[t]\n",
    "\n",
    "        return y.long().to(self.device)\n",
    "\n",
    "    def check_shape(self, x):\n",
    "        return x if len(x.shape) == (self.ndims + 1) else x.unsqueeze(0)\n",
    "\n",
    "    def random_choice(self, shape):\n",
    "        t = 2 * torch.rand(shape).to(self.device) - 1\n",
    "        return torch.sign(t)\n",
    "\n",
    "    def random_int(self, low=0, high=1, shape=None):\n",
    "        if shape is None:\n",
    "            shape = [1]\n",
    "\n",
    "        t = low + (high - low) * torch.rand(shape).to(self.device)\n",
    "        return t.long()\n",
    "\n",
    "    def normalize(self, x):\n",
    "        if self.norm == 'Linf':\n",
    "            t = x.abs().view(x.shape[0], -1).max(1)[0]\n",
    "            return x / (t.view(-1, *([1] * self.ndims)) + 1e-12)\n",
    "\n",
    "        elif self.norm == 'L2':\n",
    "            t = (x ** 2).view(x.shape[0], -1).sum(-1).sqrt()\n",
    "            return x / (t.view(-1, *([1] * self.ndims)) + 1e-12)\n",
    "\n",
    "    def lp_norm(self, x):\n",
    "        if self.norm == 'L2':\n",
    "            t = (x ** 2).view(x.shape[0], -1).sum(-1).sqrt()\n",
    "            return t.view(-1, *([1] * self.ndims))\n",
    "\n",
    "    def p_selection(self, it):\n",
    "        \"\"\" schedule to decrease the parameter p \"\"\"\n",
    "\n",
    "        if self.rescale_schedule:\n",
    "            it = int(it / self.n_queries * 10000)\n",
    "\n",
    "        if 'patches' in self.norm:\n",
    "            if 10 < it <= 50:\n",
    "                p = self.p_init / 2\n",
    "            elif 50 < it <= 200:\n",
    "                p = self.p_init / 4\n",
    "            elif 200 < it <= 500:\n",
    "                p = self.p_init / 8\n",
    "            elif 500 < it <= 1000:\n",
    "                p = self.p_init / 16\n",
    "            elif 1000 < it <= 2000:\n",
    "                p = self.p_init / 32\n",
    "            elif 2000 < it <= 4000:\n",
    "                p = self.p_init / 64\n",
    "            elif 4000 < it <= 6000:\n",
    "                p = self.p_init / 128\n",
    "            elif 6000 < it <= 8000:\n",
    "                p = self.p_init / 256\n",
    "            elif 8000 < it:\n",
    "                p = self.p_init / 512\n",
    "            else:\n",
    "                p = self.p_init\n",
    "\n",
    "        elif 'frames' in self.norm:\n",
    "            if not 'universal' in self.norm:\n",
    "                tot_qr = 10000 if self.rescale_schedule else self.n_queries\n",
    "                p = max((float(tot_qr - it) / tot_qr - .5) * self.p_init * self.eps ** 2, 0.)\n",
    "                return 3. * math.ceil(p)\n",
    "\n",
    "            else:\n",
    "                assert self.rescale_schedule\n",
    "                its = [200, 600, 1200, 1800, 2500, 10000, 100000]\n",
    "                resc_factors = [1., .8, .6, .4, .2, .1, 0.]\n",
    "                c = 0\n",
    "                while it >= its[c]:\n",
    "                    c += 1\n",
    "                return resc_factors[c] * self.p_init\n",
    "\n",
    "        elif 'L0' in self.norm:\n",
    "            if 0 < it <= 50:\n",
    "                p = self.p_init / 2\n",
    "            elif 50 < it <= 200:\n",
    "                p = self.p_init / 4\n",
    "            elif 200 < it <= 500:\n",
    "                p = self.p_init / 5\n",
    "            elif 500 < it <= 1000:\n",
    "                p = self.p_init / 6\n",
    "            elif 1000 < it <= 2000:\n",
    "                p = self.p_init / 8\n",
    "            elif 2000 < it <= 4000:\n",
    "                p = self.p_init / 10\n",
    "            elif 4000 < it <= 6000:\n",
    "                p = self.p_init / 12\n",
    "            elif 6000 < it <= 8000:\n",
    "                p = self.p_init / 15\n",
    "            elif 8000 < it:\n",
    "                p = self.p_init / 20\n",
    "            else:\n",
    "                p = self.p_init\n",
    "\n",
    "            if self.constant_schedule:\n",
    "                p = self.p_init / 2\n",
    "\n",
    "        return p\n",
    "\n",
    "    def sh_selection(self, it):\n",
    "        \"\"\" schedule to decrease the parameter p \"\"\"\n",
    "\n",
    "        t = max((float(self.n_queries - it) / self.n_queries - .0) ** 1., 0) * .75\n",
    "\n",
    "        return t\n",
    "\n",
    "    def get_init_patch(self, c, s, n_iter=1000):\n",
    "        if self.init_patches == 'stripes':\n",
    "            patch_univ = torch.zeros([1, c, s, s]).to(self.device) + self.random_choice(\n",
    "                [1, c, 1, s]).clamp(0., 1.)\n",
    "        elif self.init_patches == 'uniform':\n",
    "            patch_univ = torch.zeros([1, c, s, s]).to(self.device) + self.random_choice(\n",
    "                [1, c, 1, 1]).clamp(0., 1.)\n",
    "        elif self.init_patches == 'random':\n",
    "            patch_univ = self.random_choice([1, c, s, s]).clamp(0., 1.)\n",
    "        elif self.init_patches == 'random_squares':\n",
    "            patch_univ = torch.zeros([1, c, s, s]).to(self.device)\n",
    "            for _ in range(n_iter):\n",
    "                size_init = torch.randint(low=1, high=math.ceil(s ** .5), size=[1]).item()\n",
    "                loc_init = torch.randint(s - size_init + 1, size=[2])\n",
    "                patch_univ[0, :, loc_init[0]:loc_init[0] + size_init, loc_init[1]:loc_init[1] + size_init] = 0.\n",
    "                patch_univ[0, :, loc_init[0]:loc_init[0] + size_init, loc_init[1]:loc_init[1] + size_init\n",
    "                ] += self.random_choice([c, 1, 1]).clamp(0., 1.)\n",
    "        elif self.init_patches == 'sh':\n",
    "            patch_univ = torch.ones([1, c, s, s]).to(self.device)\n",
    "\n",
    "        return patch_univ.clamp(0., 1.)\n",
    "\n",
    "    def attack_single_run(self, x, y):\n",
    "        with torch.no_grad():\n",
    "            adv = x.clone()\n",
    "            c, h, w = x.shape[1:]\n",
    "            n_features = c * h * w\n",
    "            n_ex_total = x.shape[0]\n",
    "\n",
    "            if self.norm == 'L0':\n",
    "                eps = self.eps\n",
    "\n",
    "                x_best = x.clone()\n",
    "                n_pixels = h * w\n",
    "                b_all, be_all = torch.zeros([x.shape[0], eps]).long(), torch.zeros([x.shape[0], n_pixels - eps]).long()\n",
    "                for img in range(x.shape[0]):\n",
    "                    ind_all = torch.randperm(n_pixels)\n",
    "                    ind_p = ind_all[:eps]\n",
    "                    ind_np = ind_all[eps:]\n",
    "                    x_best[img, :, ind_p // w, ind_p % w] = self.random_choice([c, eps]).clamp(0., 1.)\n",
    "                    b_all[img] = ind_p.clone()\n",
    "                    be_all[img] = ind_np.clone()\n",
    "\n",
    "                margin_min, loss_min = self.margin_and_loss(x_best, y)\n",
    "                n_queries = torch.ones(x.shape[0]).to(self.device)\n",
    "\n",
    "                for it in range(1, self.n_queries):\n",
    "                    # check points still to fool\n",
    "                    idx_to_fool = (margin_min > 0.).nonzero().squeeze()\n",
    "                    x_curr = self.check_shape(x[idx_to_fool])\n",
    "                    x_best_curr = self.check_shape(x_best[idx_to_fool])\n",
    "                    y_curr = y[idx_to_fool]\n",
    "                    margin_min_curr = margin_min[idx_to_fool]\n",
    "                    loss_min_curr = loss_min[idx_to_fool]\n",
    "                    b_curr, be_curr = b_all[idx_to_fool], be_all[idx_to_fool]\n",
    "                    if len(y_curr.shape) == 0:\n",
    "                        y_curr.unsqueeze_(0)\n",
    "                        margin_min_curr.unsqueeze_(0)\n",
    "                        loss_min_curr.unsqueeze_(0)\n",
    "                        b_curr.unsqueeze_(0)\n",
    "                        be_curr.unsqueeze_(0)\n",
    "                        idx_to_fool.unsqueeze_(0)\n",
    "\n",
    "                    # build new candidate\n",
    "                    x_new = x_best_curr.clone()\n",
    "                    eps_it = max(int(self.p_selection(it) * eps), 1)\n",
    "                    ind_p = torch.randperm(eps)[:eps_it]\n",
    "                    ind_np = torch.randperm(n_pixels - eps)[:eps_it]\n",
    "\n",
    "                    for img in range(x_new.shape[0]):\n",
    "                        p_set = b_curr[img, ind_p]\n",
    "                        np_set = be_curr[img, ind_np]\n",
    "                        x_new[img, :, p_set // w, p_set % w] = x_curr[img, :, p_set // w, p_set % w].clone()\n",
    "                        if eps_it > 1:\n",
    "                            x_new[img, :, np_set // w, np_set % w] = self.random_choice([c, eps_it]).clamp(0., 1.)\n",
    "                        else:\n",
    "                            # if update is 1x1 make sure the sampled color is different from the current one\n",
    "                            old_clr = x_new[img, :, np_set // w, np_set % w].clone()\n",
    "                            assert old_clr.shape == (c, 1), print(old_clr)\n",
    "                            new_clr = old_clr.clone()\n",
    "                            while (new_clr == old_clr).all().item():\n",
    "                                new_clr = self.random_choice([c, 1]).clone().clamp(0., 1.)\n",
    "                            x_new[img, :, np_set // w, np_set % w] = new_clr.clone()\n",
    "\n",
    "                    # compute loss of the new candidates\n",
    "                    margin, loss = self.margin_and_loss(x_new, y_curr)\n",
    "                    n_queries[idx_to_fool] += 1\n",
    "\n",
    "                    # update best solution\n",
    "                    idx_improved = (loss < loss_min_curr).float()\n",
    "                    idx_to_update = (idx_improved > 0.).nonzero().squeeze()\n",
    "                    loss_min[idx_to_fool[idx_to_update]] = loss[idx_to_update]\n",
    "\n",
    "                    idx_miscl = (margin < -1e-6).float()\n",
    "                    idx_improved = torch.max(idx_improved, idx_miscl)\n",
    "                    nimpr = idx_improved.sum().item()\n",
    "                    if nimpr > 0.:\n",
    "                        idx_improved = (idx_improved.view(-1) > 0).nonzero().squeeze()\n",
    "                        margin_min[idx_to_fool[idx_improved]] = margin[idx_improved].clone()\n",
    "                        x_best[idx_to_fool[idx_improved]] = x_new[idx_improved].clone()\n",
    "                        t = b_curr[idx_improved].clone()\n",
    "                        te = be_curr[idx_improved].clone()\n",
    "\n",
    "                        if nimpr > 1:\n",
    "                            t[:, ind_p] = be_curr[idx_improved][:, ind_np] + 0\n",
    "                            te[:, ind_np] = b_curr[idx_improved][:, ind_p] + 0\n",
    "                        else:\n",
    "                            t[ind_p] = be_curr[idx_improved][ind_np] + 0\n",
    "                            te[ind_np] = b_curr[idx_improved][ind_p] + 0\n",
    "\n",
    "                        b_all[idx_to_fool[idx_improved]] = t.clone()\n",
    "                        be_all[idx_to_fool[idx_improved]] = te.clone()\n",
    "\n",
    "                    # log results current iteration\n",
    "                    ind_succ = (margin_min <= 0.).nonzero().squeeze()\n",
    "                    if self.verbose and ind_succ.numel() != 0:\n",
    "                        self.logger.log(' '.join(['{}'.format(it + 1),\n",
    "                                                  '- success rate={}/{} ({:.2%})'.format(\n",
    "                                                      ind_succ.numel(), n_ex_total,\n",
    "                                                      float(ind_succ.numel()) / n_ex_total),\n",
    "                                                  '- avg # queries={:.1f}'.format(\n",
    "                                                      n_queries[ind_succ].mean().item()),\n",
    "                                                  '- med # queries={:.1f}'.format(\n",
    "                                                      n_queries[ind_succ].median().item()),\n",
    "                                                  '- loss={:.3f}'.format(loss_min.mean()),\n",
    "                                                  '- max pert={:.0f}'.format(((x_new - x_curr).abs() > 0\n",
    "                                                                              ).max(1)[0].view(x_new.shape[0], -1).sum(\n",
    "                                                      -1).max()),\n",
    "                                                  '- epsit={:.0f}'.format(eps_it),\n",
    "                                                  ]))\n",
    "\n",
    "                    if ind_succ.numel() == n_ex_total:\n",
    "                        break\n",
    "\n",
    "            elif self.norm == 'patches':\n",
    "                ''' assumes square images and patches '''\n",
    "\n",
    "                s = int(math.ceil(self.eps ** .5))\n",
    "                x_best = x.clone()\n",
    "                x_new = x.clone()\n",
    "                loc = torch.randint(h - s, size=[x.shape[0], 2])\n",
    "                patches_coll = torch.zeros([x.shape[0], c, s, s]).to(self.device)\n",
    "                assert abs(self.update_loc_period) > 1\n",
    "                loc_t = abs(self.update_loc_period)\n",
    "\n",
    "                # set when to start single channel updates\n",
    "                it_start_cu = None\n",
    "                for it in range(0, self.n_queries):\n",
    "                    s_it = int(max(self.p_selection(it) ** .5 * s, 1))\n",
    "                    if s_it == 1:\n",
    "                        break\n",
    "                it_start_cu = it + (self.n_queries - it) // 2\n",
    "                if self.verbose:\n",
    "                    self.logger.log('starting single channel updates at query {}'.format(\n",
    "                        it_start_cu))\n",
    "\n",
    "                # initialize patches\n",
    "                if self.verbose:\n",
    "                    self.logger.log('using {} initialization'.format(self.init_patches))\n",
    "                for counter in range(x.shape[0]):\n",
    "                    patches_coll[counter] += self.get_init_patch(c, s).squeeze().clamp(0., 1.)\n",
    "                    x_new[counter, :, loc[counter, 0]:loc[counter, 0] + s,\n",
    "                    loc[counter, 1]:loc[counter, 1] + s] = patches_coll[counter].clone()\n",
    "\n",
    "                margin_min, loss_min = self.margin_and_loss(x_new, y)\n",
    "                n_queries = torch.ones(x.shape[0]).to(self.device)\n",
    "\n",
    "                for it in range(1, self.n_queries):\n",
    "                    # check points still to fool\n",
    "                    idx_to_fool = (margin_min > -1e-6).nonzero().squeeze()\n",
    "                    x_curr = self.check_shape(x[idx_to_fool])\n",
    "                    patches_curr = self.check_shape(patches_coll[idx_to_fool])\n",
    "                    y_curr = y[idx_to_fool]\n",
    "                    margin_min_curr = margin_min[idx_to_fool]\n",
    "                    loss_min_curr = loss_min[idx_to_fool]\n",
    "                    loc_curr = loc[idx_to_fool]\n",
    "                    if len(y_curr.shape) == 0:\n",
    "                        y_curr.unsqueeze_(0)\n",
    "                        margin_min_curr.unsqueeze_(0)\n",
    "                        loss_min_curr.unsqueeze_(0)\n",
    "\n",
    "                        loc_curr.unsqueeze_(0)\n",
    "                        idx_to_fool.unsqueeze_(0)\n",
    "\n",
    "                    # sample update\n",
    "                    s_it = int(max(self.p_selection(it) ** .5 * s, 1))\n",
    "                    p_it = torch.randint(s - s_it + 1, size=[2])\n",
    "                    sh_it = int(max(self.sh_selection(it) * h, 0))\n",
    "                    patches_new = patches_curr.clone()\n",
    "                    x_new = x_curr.clone()\n",
    "                    loc_new = loc_curr.clone()\n",
    "                    update_loc = int((it % loc_t == 0) and (sh_it > 0))\n",
    "                    update_patch = 1. - update_loc\n",
    "                    if self.update_loc_period < 0 and sh_it > 0:\n",
    "                        update_loc = 1. - update_loc\n",
    "                        update_patch = 1. - update_patch\n",
    "                    for counter in range(x_curr.shape[0]):\n",
    "                        if update_patch == 1.:\n",
    "                            # update patch\n",
    "                            if it < it_start_cu:\n",
    "                                if s_it > 1:\n",
    "                                    patches_new[counter, :, p_it[0]:p_it[0] + s_it,\n",
    "                                    p_it[1]:p_it[1] + s_it] += self.random_choice([c, 1, 1])\n",
    "                                else:\n",
    "                                    # make sure to sample a different color\n",
    "                                    old_clr = patches_new[counter, :, p_it[0]:p_it[0] + s_it,\n",
    "                                              p_it[1]:p_it[1] + s_it].clone()\n",
    "                                    new_clr = old_clr.clone()\n",
    "                                    while (new_clr == old_clr).all().item():\n",
    "                                        new_clr = self.random_choice([c, 1, 1]).clone().clamp(0., 1.)\n",
    "                                    patches_new[counter, :, p_it[0]:p_it[0] + s_it,\n",
    "                                    p_it[1]:p_it[1] + s_it] = new_clr.clone()\n",
    "                            else:\n",
    "                                assert s_it == 1\n",
    "                                assert it >= it_start_cu\n",
    "                                # single channel updates\n",
    "                                new_ch = self.random_int(low=0, high=3, shape=[1])\n",
    "                                patches_new[counter, new_ch, p_it[0]:p_it[0] + s_it,\n",
    "                                p_it[1]:p_it[1] + s_it] = 1. - patches_new[\n",
    "                                                               counter, new_ch, p_it[0]:p_it[0] + s_it,\n",
    "                                                               p_it[1]:p_it[1] + s_it]\n",
    "\n",
    "                            patches_new[counter].clamp_(0., 1.)\n",
    "                        if update_loc == 1:\n",
    "                            # update location\n",
    "                            loc_new[counter] += (torch.randint(low=-sh_it, high=sh_it + 1, size=[2]))\n",
    "                            loc_new[counter].clamp_(0, h - s)\n",
    "\n",
    "                        x_new[counter, :, loc_new[counter, 0]:loc_new[counter, 0] + s,\n",
    "                        loc_new[counter, 1]:loc_new[counter, 1] + s] = patches_new[counter].clone()\n",
    "\n",
    "                    # check loss of new candidate\n",
    "                    margin, loss = self.margin_and_loss(x_new, y_curr)\n",
    "                    n_queries[idx_to_fool] += 1\n",
    "\n",
    "                    # update best solution\n",
    "                    idx_improved = (loss < loss_min_curr).float()\n",
    "                    idx_to_update = (idx_improved > 0.).nonzero().squeeze()\n",
    "                    loss_min[idx_to_fool[idx_to_update]] = loss[idx_to_update]\n",
    "\n",
    "                    idx_miscl = (margin < -1e-6).float()\n",
    "                    idx_improved = torch.max(idx_improved, idx_miscl)\n",
    "                    nimpr = idx_improved.sum().item()\n",
    "                    if nimpr > 0.:\n",
    "                        idx_improved = (idx_improved.view(-1) > 0).nonzero().squeeze()\n",
    "                        margin_min[idx_to_fool[idx_improved]] = margin[idx_improved].clone()\n",
    "                        patches_coll[idx_to_fool[idx_improved]] = patches_new[idx_improved].clone()\n",
    "                        loc[idx_to_fool[idx_improved]] = loc_new[idx_improved].clone()\n",
    "\n",
    "                    # log results current iteration\n",
    "                    ind_succ = (margin_min <= 0.).nonzero().squeeze()\n",
    "                    if self.verbose and ind_succ.numel() != 0:\n",
    "                        self.logger.log(' '.join(['{}'.format(it + 1),\n",
    "                                                  '- success rate={}/{} ({:.2%})'.format(\n",
    "                                                      ind_succ.numel(), n_ex_total,\n",
    "                                                      float(ind_succ.numel()) / n_ex_total),\n",
    "                                                  '- avg # queries={:.1f}'.format(\n",
    "                                                      n_queries[ind_succ].mean().item()),\n",
    "                                                  '- med # queries={:.1f}'.format(\n",
    "                                                      n_queries[ind_succ].median().item()),\n",
    "                                                  '- loss={:.3f}'.format(loss_min.mean()),\n",
    "                                                  '- max pert={:.0f}'.format(((x_new - x_curr).abs() > 0\n",
    "                                                                              ).max(1)[0].view(x_new.shape[0], -1).sum(\n",
    "                                                      -1).max()),\n",
    "                                                  # '- sit={:.0f} - sh={:.0f}'.format(s_it, sh_it),\n",
    "                                                  '{}'.format(' - loc' if update_loc == 1. else ''),\n",
    "                                                  ]))\n",
    "\n",
    "                    if ind_succ.numel() == n_ex_total:\n",
    "                        break\n",
    "\n",
    "                # apply patches\n",
    "                for counter in range(x.shape[0]):\n",
    "                    x_best[counter, :, loc[counter, 0]:loc[counter, 0] + s,\n",
    "                    loc[counter, 1]:loc[counter, 1] + s] = patches_coll[counter].clone()\n",
    "\n",
    "            elif self.norm == 'patches_universal':\n",
    "                ''' assumes square images and patches '''\n",
    "\n",
    "                s = int(math.ceil(self.eps ** .5))\n",
    "                x_best = x.clone()\n",
    "                self.n_imgs = x.shape[0]\n",
    "                x_new = x.clone()\n",
    "                loc = torch.randint(h - s + 1, size=[x.shape[0], 2])\n",
    "\n",
    "                # set when to start single channel updates\n",
    "                it_start_cu = None\n",
    "                for it in range(0, self.n_queries):\n",
    "                    s_it = int(max(self.p_selection(it) ** .5 * s, 1))\n",
    "                    if s_it == 1:\n",
    "                        break\n",
    "                it_start_cu = it + (self.n_queries - it) // 2\n",
    "                if self.verbose:\n",
    "                    self.logger.log('starting single channel updates at query {}'.format(\n",
    "                        it_start_cu))\n",
    "\n",
    "                # initialize patch\n",
    "                if self.verbose:\n",
    "                    self.logger.log('using {} initialization'.format(self.init_patches))\n",
    "                patch_univ = self.get_init_patch(c, s)\n",
    "                it_init = 0\n",
    "\n",
    "                loss_batch = float(1e10)\n",
    "                n_succs = 0\n",
    "                n_iter = self.n_queries\n",
    "\n",
    "                # init update batch\n",
    "                assert not self.data_loader is None\n",
    "                assert not self.resample_loc is None\n",
    "                assert self.targeted\n",
    "                new_train_imgs = []\n",
    "                n_newimgs = self.n_imgs + 0\n",
    "                n_imgsneeded = math.ceil(self.n_queries / self.resample_loc) * n_newimgs\n",
    "                tot_imgs = 0\n",
    "                if self.verbose:\n",
    "                    self.logger.log('imgs updated={}, imgs needed={}'.format(\n",
    "                        n_newimgs, n_imgsneeded))\n",
    "                while tot_imgs < min(100000, n_imgsneeded):\n",
    "                    x_toupdatetrain, _ = next(self.data_loader)\n",
    "                    new_train_imgs.append(x_toupdatetrain)\n",
    "                    tot_imgs += x_toupdatetrain.shape[0]\n",
    "                newimgstoadd = torch.cat(new_train_imgs, axis=0)\n",
    "                counter_resamplingimgs = 0\n",
    "\n",
    "                for it in range(it_init, n_iter):\n",
    "                    # sample size and location of the update\n",
    "                    s_it = int(max(self.p_selection(it) ** .5 * s, 1))\n",
    "                    p_it = torch.randint(s - s_it + 1, size=[2])\n",
    "\n",
    "                    patch_new = patch_univ.clone()\n",
    "\n",
    "                    if s_it > 1:\n",
    "                        patch_new[0, :, p_it[0]:p_it[0] + s_it, p_it[1]:p_it[1] + s_it] += self.random_choice([c, 1, 1])\n",
    "                    else:\n",
    "                        old_clr = patch_new[0, :, p_it[0]:p_it[0] + s_it, p_it[1]:p_it[1] + s_it].clone()\n",
    "                        new_clr = old_clr.clone()\n",
    "                        if it < it_start_cu:\n",
    "                            while (new_clr == old_clr).all().item():\n",
    "                                new_clr = self.random_choice(new_clr).clone().clamp(0., 1.)\n",
    "                        else:\n",
    "                            # single channel update\n",
    "                            new_ch = self.random_int(low=0, high=3, shape=[1])\n",
    "                            new_clr[new_ch] = 1. - new_clr[new_ch]\n",
    "\n",
    "                        patch_new[0, :, p_it[0]:p_it[0] + s_it, p_it[1]:p_it[1] + s_it] = new_clr.clone()\n",
    "\n",
    "                    patch_new.clamp_(0., 1.)\n",
    "\n",
    "                    # compute loss for new candidate\n",
    "                    x_new = x.clone()\n",
    "\n",
    "                    for counter in range(x.shape[0]):\n",
    "                        loc_new = loc[counter]\n",
    "                        x_new[counter, :, loc_new[0]:loc_new[0] + s, loc_new[1]:loc_new[1] + s] = 0.\n",
    "                        x_new[counter, :, loc_new[0]:loc_new[0] + s, loc_new[1]:loc_new[1] + s] += patch_new[0]\n",
    "\n",
    "                    margin_run, loss_run = self.margin_and_loss(x_new, y)\n",
    "                    if self.loss == 'ce':\n",
    "                        loss_run += x_new.shape[0]\n",
    "                    loss_new = loss_run.sum()\n",
    "                    n_succs_new = (margin_run < -1e-6).sum().item()\n",
    "\n",
    "                    # accept candidate if loss improves\n",
    "                    if loss_new < loss_batch:\n",
    "                        is_accepted = True\n",
    "                        loss_batch = loss_new + 0.\n",
    "                        patch_univ = patch_new.clone()\n",
    "                        n_succs = n_succs_new + 0\n",
    "                    else:\n",
    "                        is_accepted = False\n",
    "\n",
    "                    # sample new locations and images\n",
    "                    if (it + 1) % self.resample_loc == 0:\n",
    "                        newimgstoadd_it = newimgstoadd[counter_resamplingimgs * n_newimgs:(\n",
    "                                                                                                  counter_resamplingimgs + 1) * n_newimgs].clone().cuda()\n",
    "                        new_batch = [x[n_newimgs:].clone(), newimgstoadd_it.clone()]\n",
    "                        x = torch.cat(new_batch, dim=0)\n",
    "                        assert x.shape[0] == self.n_imgs\n",
    "\n",
    "                        loc = torch.randint(h - s + 1, size=[self.n_imgs, 2])\n",
    "                        assert loc.shape == (self.n_imgs, 2)\n",
    "\n",
    "                        loss_batch = loss_batch * 0. + 1e6\n",
    "                        counter_resamplingimgs += 1\n",
    "\n",
    "                    # logging current iteration\n",
    "                    if self.verbose:\n",
    "                        self.logger.log(' '.join(['{}'.format(it + 1),\n",
    "                                                  '- success rate={}/{} ({:.2%})'.format(\n",
    "                                                      n_succs, n_ex_total,\n",
    "                                                      float(n_succs) / n_ex_total),\n",
    "                                                  '- loss={:.3f}'.format(loss_batch),\n",
    "                                                  '- max pert={:.0f}'.format(((x_new - x).abs() > 0\n",
    "                                                                              ).max(1)[0].view(x_new.shape[0], -1).sum(\n",
    "                                                      -1).max()),\n",
    "                                                  ]))\n",
    "\n",
    "                # apply patches on the initial images\n",
    "                for counter in range(x_best.shape[0]):\n",
    "                    loc_new = loc[counter]\n",
    "                    x_best[counter, :, loc_new[0]:loc_new[0] + s, loc_new[1]:loc_new[1] + s] = 0.\n",
    "                    x_best[counter, :, loc_new[0]:loc_new[0] + s, loc_new[1]:loc_new[1] + s] += patch_univ[0]\n",
    "\n",
    "            elif self.norm == 'frames':\n",
    "                # set width and indices of frames\n",
    "                mask = torch.zeros(x.shape[-2:])\n",
    "                s = self.eps + 0\n",
    "                mask[:s] = 1.\n",
    "                mask[-s:] = 1.\n",
    "                mask[:, :s] = 1.\n",
    "                mask[:, -s:] = 1.\n",
    "                ind = (mask == 1.).nonzero().squeeze()\n",
    "                eps = ind.shape[0]\n",
    "                x_best = x.clone()\n",
    "                x_new = x.clone()\n",
    "                mask = mask.view(1, 1, h, w).to(self.device)\n",
    "                mask_frame = torch.ones([1, c, h, w], device=x.device) * mask\n",
    "                #\n",
    "\n",
    "                # set when starting single channel updates\n",
    "                it_start_cu = None\n",
    "                for it in range(0, self.n_queries):\n",
    "                    s_it = int(max(self.p_selection(it), 1))\n",
    "                    if s_it == 1:\n",
    "                        break\n",
    "                it_start_cu = it + (self.n_queries - it) // 2\n",
    "                # it_start_cu = 10000\n",
    "                if self.verbose:\n",
    "                    self.logger.log('starting single channel updates at query {}'.format(\n",
    "                        it_start_cu))\n",
    "\n",
    "                # initialize frames\n",
    "                x_best[:, :, ind[:, 0], ind[:, 1]] = self.random_choice(\n",
    "                    [x.shape[0], c, eps]).clamp(0., 1.)\n",
    "\n",
    "                margin_min, loss_min = self.margin_and_loss(x_best, y)\n",
    "                n_queries = torch.ones(x.shape[0]).to(self.device)\n",
    "\n",
    "                for it in range(1, self.n_queries):\n",
    "                    # check points still to fool\n",
    "                    idx_to_fool = (margin_min > -1e-6).nonzero().squeeze()\n",
    "                    x_curr = self.check_shape(x[idx_to_fool])\n",
    "                    x_best_curr = self.check_shape(x_best[idx_to_fool])\n",
    "                    y_curr = y[idx_to_fool]\n",
    "                    margin_min_curr = margin_min[idx_to_fool]\n",
    "                    loss_min_curr = loss_min[idx_to_fool]\n",
    "\n",
    "                    if len(y_curr.shape) == 0:\n",
    "                        y_curr.unsqueeze_(0)\n",
    "                        margin_min_curr.unsqueeze_(0)\n",
    "                        loss_min_curr.unsqueeze_(0)\n",
    "                        idx_to_fool.unsqueeze_(0)\n",
    "\n",
    "                    # sample update\n",
    "                    s_it = max(int(self.p_selection(it)), 1)\n",
    "                    ind_it = torch.randperm(eps)[0]\n",
    "\n",
    "                    x_new = x_best_curr.clone()\n",
    "                    if s_it > 1:\n",
    "                        dir_h = self.random_choice([1]).long().cpu()\n",
    "                        dir_w = self.random_choice([1]).long().cpu()\n",
    "                        new_clr = self.random_choice([c, 1]).clamp(0., 1.)\n",
    "\n",
    "                    for counter in range(x_curr.shape[0]):\n",
    "                        if s_it > 1:\n",
    "                            for counter_h in range(s_it):\n",
    "                                for counter_w in range(s_it):\n",
    "                                    x_new[counter, :, (ind[ind_it, 0] + dir_h * counter_h).clamp(0, h - 1),\n",
    "                                    (ind[ind_it, 1] + dir_w * counter_w).clamp(0, w - 1)] = new_clr.clone()\n",
    "                        else:\n",
    "                            p_it = ind[ind_it].clone()\n",
    "                            old_clr = x_new[counter, :, p_it[0]:p_it[0] + s_it, p_it[1]:p_it[1] + s_it].clone()\n",
    "                            new_clr = old_clr.clone()\n",
    "                            if it < it_start_cu:\n",
    "                                while (new_clr == old_clr).all().item():\n",
    "                                    new_clr = self.random_choice([c, 1, 1]).clone().clamp(0., 1.)\n",
    "                            else:\n",
    "                                # single channel update\n",
    "                                new_ch = self.random_int(low=0, high=3, shape=[1])\n",
    "                                new_clr[new_ch] = 1. - new_clr[new_ch]\n",
    "                            x_new[counter, :, p_it[0]:p_it[0] + s_it, p_it[1]:p_it[1] + s_it] = new_clr.clone()\n",
    "\n",
    "                    x_new.clamp_(0., 1.)\n",
    "                    x_new = (x_new - x_curr) * mask_frame + x_curr\n",
    "\n",
    "                    # check loss of new candidate\n",
    "                    margin, loss = self.margin_and_loss(x_new, y_curr)\n",
    "                    n_queries[idx_to_fool] += 1\n",
    "\n",
    "                    # update best solution\n",
    "                    idx_improved = (loss < loss_min_curr).float()\n",
    "                    idx_to_update = (idx_improved > 0.).nonzero().squeeze()\n",
    "                    loss_min[idx_to_fool[idx_to_update]] = loss[idx_to_update]\n",
    "\n",
    "                    idx_miscl = (margin < -1e-6).float()\n",
    "                    idx_improved = torch.max(idx_improved, idx_miscl)\n",
    "                    nimpr = idx_improved.sum().item()\n",
    "                    if nimpr > 0.:\n",
    "                        idx_improved = (idx_improved.view(-1) > 0).nonzero().squeeze()\n",
    "                        margin_min[idx_to_fool[idx_improved]] = margin[idx_improved].clone()\n",
    "                        x_best[idx_to_fool[idx_improved]] = x_new[idx_improved].clone()\n",
    "\n",
    "                    # log results current iteration\n",
    "                    ind_succ = (margin_min <= 0.).nonzero().squeeze()\n",
    "                    if self.verbose and ind_succ.numel() != 0:\n",
    "                        self.logger.log(' '.join(['{}'.format(it + 1),\n",
    "                                                  '- success rate={}/{} ({:.2%})'.format(\n",
    "                                                      ind_succ.numel(), n_ex_total,\n",
    "                                                      float(ind_succ.numel()) / n_ex_total),\n",
    "                                                  '- avg # queries={:.1f}'.format(\n",
    "                                                      n_queries[ind_succ].mean().item()),\n",
    "                                                  '- med # queries={:.1f}'.format(\n",
    "                                                      n_queries[ind_succ].median().item()),\n",
    "                                                  '- loss={:.3f}'.format(loss_min.mean()),\n",
    "                                                  '- max pert={:.0f}'.format(((x_new - x_curr).abs() > 0\n",
    "                                                                              ).max(1)[0].view(x_new.shape[0], -1).sum(\n",
    "                                                      -1).max()),\n",
    "                                                  # '- min pert={:.0f}'.format(((x_new - x_curr).abs() > 0\n",
    "                                                  # ).max(1)[0].view(x_new.shape[0], -1).sum(-1).min()),\n",
    "                                                  # '- sit={:.0f} - indit={}'.format(s_it, ind_it.item()),\n",
    "                                                  ]))\n",
    "\n",
    "                    if ind_succ.numel() == n_ex_total:\n",
    "                        break\n",
    "\n",
    "\n",
    "            elif self.norm == 'frames_universal':\n",
    "                # set width and indices of frames\n",
    "                mask = torch.zeros(x.shape[-2:])\n",
    "                s = self.eps + 0\n",
    "                mask[:s] = 1.\n",
    "                mask[-s:] = 1.\n",
    "                mask[:, :s] = 1.\n",
    "                mask[:, -s:] = 1.\n",
    "                ind = (mask == 1.).nonzero().squeeze()\n",
    "                eps = ind.shape[0]\n",
    "                x_best = x.clone()\n",
    "                x_new = x.clone()\n",
    "                mask = mask.view(1, 1, h, w).to(self.device)\n",
    "                mask_frame = torch.ones([1, c, h, w], device=x.device) * mask\n",
    "                frame_univ = self.random_choice([1, c, eps]).clamp(0., 1.)\n",
    "\n",
    "                # set when to start single channel updates\n",
    "                it_start_cu = None\n",
    "                for it in range(0, self.n_queries):\n",
    "                    s_it = int(max(self.p_selection(it) * s, 1))\n",
    "                    if s_it == 1:\n",
    "                        break\n",
    "                it_start_cu = it + (self.n_queries - it) // 2\n",
    "                if self.verbose:\n",
    "                    self.logger.log('starting single channel updates at query {}'.format(\n",
    "                        it_start_cu))\n",
    "\n",
    "                self.n_imgs = x.shape[0]\n",
    "                loss_batch = float(1e10)\n",
    "                n_queries = torch.ones_like(y).float()\n",
    "\n",
    "                # init update batch\n",
    "                assert not self.data_loader is None\n",
    "                assert not self.resample_loc is None\n",
    "                assert self.targeted\n",
    "                new_train_imgs = []\n",
    "                n_newimgs = self.n_imgs + 0\n",
    "                n_imgsneeded = math.ceil(self.n_queries / self.resample_loc) * n_newimgs\n",
    "                tot_imgs = 0\n",
    "                if self.verbose:\n",
    "                    self.logger.log('imgs updated={}, imgs needed={}'.format(\n",
    "                        n_newimgs, n_imgsneeded))\n",
    "                while tot_imgs < min(100000, n_imgsneeded):\n",
    "                    x_toupdatetrain, _ = next(self.data_loader)\n",
    "                    new_train_imgs.append(x_toupdatetrain)\n",
    "                    tot_imgs += x_toupdatetrain.shape[0]\n",
    "                newimgstoadd = torch.cat(new_train_imgs, axis=0)\n",
    "                counter_resamplingimgs = 0\n",
    "\n",
    "                for it in range(self.n_queries):\n",
    "                    # sample update\n",
    "                    s_it = max(int(self.p_selection(it) * self.eps), 1)\n",
    "                    ind_it = torch.randperm(eps)[0]\n",
    "\n",
    "                    mask_frame[:, :, ind[:, 0], ind[:, 1]] = 0\n",
    "                    mask_frame[:, :, ind[:, 0], ind[:, 1]] += frame_univ\n",
    "\n",
    "                    if s_it > 1:\n",
    "                        dir_h = self.random_choice([1]).long().cpu()\n",
    "                        dir_w = self.random_choice([1]).long().cpu()\n",
    "                        new_clr = self.random_choice([c, 1]).clamp(0., 1.)\n",
    "\n",
    "                        for counter_h in range(s_it):\n",
    "                            for counter_w in range(s_it):\n",
    "                                mask_frame[0, :, (ind[ind_it, 0] + dir_h * counter_h).clamp(0, h - 1),\n",
    "                                (ind[ind_it, 1] + dir_w * counter_w).clamp(0, w - 1)] = new_clr.clone()\n",
    "                    else:\n",
    "                        p_it = ind[ind_it]\n",
    "                        old_clr = mask_frame[0, :, p_it[0]:p_it[0] + s_it, p_it[1]:p_it[1] + s_it].clone()\n",
    "                        new_clr = old_clr.clone()\n",
    "                        if it < it_start_cu:\n",
    "                            while (new_clr == old_clr).all().item():\n",
    "                                new_clr = self.random_choice([c, 1, 1]).clone().clamp(0., 1.)\n",
    "                        else:\n",
    "                            # single channel update\n",
    "                            new_ch = self.random_int(low=0, high=3, shape=[1])\n",
    "                            new_clr[new_ch] = 1. - new_clr[new_ch]\n",
    "                        mask_frame[0, :, p_it[0]:p_it[0] + s_it, p_it[1]:p_it[1] + s_it] = new_clr.clone()\n",
    "\n",
    "                    frame_new = mask_frame[:, :, ind[:, 0], ind[:, 1]].clone()\n",
    "                    frame_new.clamp_(0., 1.)\n",
    "                    if len(frame_new.shape) == 2:\n",
    "                        frame_new.unsqueeze_(0)\n",
    "\n",
    "                    x_new[:, :, ind[:, 0], ind[:, 1]] = 0.\n",
    "                    x_new[:, :, ind[:, 0], ind[:, 1]] += frame_new\n",
    "\n",
    "                    margin_run, loss_run = self.margin_and_loss(x_new, y)\n",
    "                    if self.loss == 'ce':\n",
    "                        loss_run += x_new.shape[0]\n",
    "                    loss_new = loss_run.sum()\n",
    "                    n_succs_new = (margin_run < -1e-6).sum().item()\n",
    "\n",
    "                    # accept candidate if loss improves\n",
    "                    if loss_new < loss_batch:\n",
    "                        # is_accepted = True\n",
    "                        loss_batch = loss_new + 0.\n",
    "                        frame_univ = frame_new.clone()\n",
    "                        n_succs = n_succs_new + 0\n",
    "\n",
    "                    # sample new images\n",
    "                    if (it + 1) % self.resample_loc == 0:\n",
    "                        newimgstoadd_it = newimgstoadd[counter_resamplingimgs * n_newimgs:(\n",
    "                                                                                                  counter_resamplingimgs + 1) * n_newimgs].clone().cuda()\n",
    "                        new_batch = [x[n_newimgs:].clone(), newimgstoadd_it.clone()]\n",
    "                        x = torch.cat(new_batch, dim=0)\n",
    "                        assert x.shape[0] == self.n_imgs\n",
    "\n",
    "                        loss_batch = loss_batch * 0. + 1e6\n",
    "                        x_new = x.clone()\n",
    "                        counter_resamplingimgs += 1\n",
    "\n",
    "                    # loggin current iteration\n",
    "                    if self.verbose:\n",
    "                        self.logger.log(' '.join(['{}'.format(it + 1),\n",
    "                                                  '- success rate={}/{} ({:.2%})'.format(\n",
    "                                                      n_succs, n_ex_total,\n",
    "                                                      float(n_succs) / n_ex_total),\n",
    "                                                  '- loss={:.3f}'.format(loss_batch),\n",
    "                                                  '- max pert={:.0f}'.format(((x_new - x).abs() > 0\n",
    "                                                                              ).max(1)[0].view(x_new.shape[0], -1).sum(\n",
    "                                                      -1).max()),\n",
    "                                                  ]))\n",
    "\n",
    "                # apply frame on initial images\n",
    "                x_best[:, :, ind[:, 0], ind[:, 1]] = 0.\n",
    "                x_best[:, :, ind[:, 0], ind[:, 1]] += frame_univ\n",
    "\n",
    "        return n_queries, x_best\n",
    "\n",
    "    def perturb(self, x, y=None):\n",
    "        \"\"\"\n",
    "        :param x:           clean images\n",
    "        :param y:           untargeted attack -> clean labels,\n",
    "                            if None we use the predicted labels\n",
    "                            targeted attack -> target labels, if None random classes,\n",
    "                            different from the predicted ones, are sampled\n",
    "        \"\"\"\n",
    "\n",
    "        self.init_hyperparam(x)\n",
    "\n",
    "        adv = x.clone()\n",
    "        qr = torch.zeros([x.shape[0]]).to(self.device)\n",
    "        if y is None:\n",
    "            if not self.targeted:\n",
    "                with torch.no_grad():\n",
    "                    output = self.predict(x)\n",
    "                    y_pred = output.max(1)[1]\n",
    "                    y = y_pred.detach().clone().long().to(self.device)\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    output = self.predict(x)\n",
    "                    n_classes = output.shape[-1]\n",
    "                    y_pred = output.max(1)[1]\n",
    "                    y = self.random_target_classes(y_pred, n_classes)\n",
    "        else:\n",
    "            y = y.detach().clone().long().to(self.device)\n",
    "\n",
    "        if not self.targeted:\n",
    "            acc = self.predict(x).max(1)[1] == y\n",
    "        else:\n",
    "            acc = self.predict(x).max(1)[1] != y\n",
    "\n",
    "        startt = time.time()\n",
    "\n",
    "        torch.random.manual_seed(self.seed)\n",
    "        torch.cuda.random.manual_seed(self.seed)\n",
    "        np.random.seed(self.seed)\n",
    "\n",
    "        for counter in range(self.n_restarts):\n",
    "            ind_to_fool = acc.nonzero().squeeze()\n",
    "            if len(ind_to_fool.shape) == 0:\n",
    "                ind_to_fool = ind_to_fool.unsqueeze(0)\n",
    "            if ind_to_fool.numel() != 0:\n",
    "                x_to_fool = x[ind_to_fool].clone()\n",
    "                y_to_fool = y[ind_to_fool].clone()\n",
    "\n",
    "                qr_curr, adv_curr = self.attack_single_run(x_to_fool, y_to_fool)\n",
    "\n",
    "                output_curr = self.predict(adv_curr)\n",
    "                if not self.targeted:\n",
    "                    acc_curr = output_curr.max(1)[1] == y_to_fool\n",
    "                else:\n",
    "                    acc_curr = output_curr.max(1)[1] != y_to_fool\n",
    "                ind_curr = (acc_curr == 0).nonzero().squeeze()\n",
    "\n",
    "                acc[ind_to_fool[ind_curr]] = 0\n",
    "                adv[ind_to_fool[ind_curr]] = adv_curr[ind_curr].clone()\n",
    "                qr[ind_to_fool[ind_curr]] = qr_curr[ind_curr].clone()\n",
    "                if self.verbose:\n",
    "                    print('restart {} - robust accuracy: {:.2%}'.format(\n",
    "                        counter, acc.float().mean()),\n",
    "                        '- cum. time: {:.1f} s'.format(\n",
    "                            time.time() - startt))\n",
    "\n",
    "        return qr, adv\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preparation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "temp_dataset = datasets.MNIST(root='data', train=True, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "temp_loader = DataLoader(\n",
    "        dataset=temp_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = next(iter(temp_loader))\n",
    "mean = data[0].mean()\n",
    "std = data[0].std()\n",
    "\n",
    "transformers = transforms.Compose([\n",
    "        transforms.RandomAffine(degrees = 30),\n",
    "        transforms.RandomPerspective(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)])\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "        root='data', train=True, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_dataset_transformed = datasets.MNIST(\n",
    "        root='data', train=True, download=True, transform=transformers)\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "        root='data', train=False, download=True, transform=transforms.ToTensor())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_dataset = ConcatDataset([train_dataset, train_dataset_transformed])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_subset, valid_subset = torch.utils.data.random_split(\n",
    "        final_dataset, [100_000, 20_000], generator=torch.Generator())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "        dataset=train_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "        dataset=valid_subset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "        dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataloaders_dict = {'train': train_loader, 'val': valid_loader}\n",
    "dataset_sizes_dict = {'train': len(train_subset), 'val': len(valid_subset)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Definitions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, attack, dataloaders, dataset_sizes, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in ['train', 'val']:\n",
    "\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                if attack:\n",
    "                    inputs = attack(inputs)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, predictions = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(predictions == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            logger.info('epoch:{} phase:{}'.format(epoch + 1, phase))\n",
    "            logger.info(\n",
    "                '{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "\n",
    "    logger.info(\n",
    "        'Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    logger.info(\n",
    "        'Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "resnet = models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "epochs = 20\n",
    "\n",
    "resnet.conv1 = \\\n",
    "        nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "resnet.fc = \\\n",
    "        nn.Linear(resnet.fc.in_features, 10)\n",
    "\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "criterion_md = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_md = optim.Adam(resnet.parameters(), lr=0.001)\n",
    "\n",
    "lr_scheduler_md = lr_scheduler.StepLR(optimizer_md, step_size=5, gamma=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "adversary = RSAttack(resnet, norm='L0', eps=20, verbose=True, n_queries=5_000, loss='ce')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train model\n",
    "model_ft = train_model(\n",
    "        resnet, criterion_md, optimizer_md, lr_scheduler_md, adversary.perturb,\n",
    "        dataloaders_dict, dataset_sizes_dict, num_epochs=epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prediction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict(model, dataloader):\n",
    "\n",
    "    test_pred = torch.LongTensor()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for images in dataloader:\n",
    "\n",
    "            images = torch.autograd.Variable(images[0])\n",
    "            if torch.cuda.is_available():\n",
    "                images = images.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            predicted = outputs.cpu().data.max(1, keepdim=True)[1]\n",
    "            test_pred = torch.cat((test_pred, predicted), dim=0)\n",
    "\n",
    "    return test_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = predict(resnet, test_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}